<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Cloud-Wong</title>
  <subtitle>HySy Art Mask Studio</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-02-01T08:10:31.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>黄耘</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【Kaggle泰坦尼克号】用决策树快速的撸一个Baseline</title>
    <link href="http://yoursite.com/2019/01/31/kaggle-Titanic/"/>
    <id>http://yoursite.com/2019/01/31/kaggle-Titanic/</id>
    <published>2019-01-31T04:50:17.000Z</published>
    <updated>2019-02-01T08:10:31.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h1><p>检验学习成果最快的方式就是去实战，kaggle上提供了各式各样练手和比赛的数据集，”Titanic: Machine Learning from Disaster”就是最经典的入门比赛，既适合经验丰富的Data scientist去深入分析争取top3%的成绩，也适合新手应用数据集对所学习的分类算法来练手。</p>
<blockquote>
<p>应用机器学习，千万不要一上来就试图做到完美，先撸一个baseline的model出来，再进行后续的分析步骤，一步步提高。—— Andrew Ng</p>
</blockquote>
<a id="more"></a>
<p>本篇就是基于决策树模型快速的撸一个baseline model。</p>
<p>选择决策树的原因：模型对数据的要求不高，一般原始数据简单的预处理就能让模型跑起来（如果要得到更高的分数，数据预处理特征工程还是不能少）</p>
<h1 id="2-泰坦尼克号背景介绍"><a href="#2-泰坦尼克号背景介绍" class="headerlink" title="2. 泰坦尼克号背景介绍"></a>2. 泰坦尼克号背景介绍</h1><p><img src="https://image.littlebeans.cn/images/2019/01/31/e8e2a12a050c40c1b6ff2e39bf227ae6_th.jpg" alt="e8e2a12a050c40c1b6ff2e39bf227ae6_th.jpg"></p>
<blockquote>
<p>泰坦尼克号的沉没是历史上最臭名昭著的沉船之一，泰坦尼克号在首航中撞上冰山沉没，2224名乘客和船员中1502人遇难。这一耸人听闻的悲剧震惊了国际社会，并导致了对船舶更严格的安全规定。</p>
</blockquote>
<p>我们的任务是运用机器学习的工具，分析船上人员的信息来预测什么样的人能够从船难中活下来。</p>
<h1 id="3-数据集分析"><a href="#3-数据集分析" class="headerlink" title="3. 数据集分析"></a>3. 数据集分析</h1><h2 id="3-1-特征介绍"><a href="#3-1-特征介绍" class="headerlink" title="3.1 特征介绍"></a>3.1 特征介绍</h2><div class="table-container">
<table>
<thead>
<tr>
<th><strong>Variable</strong></th>
<th><strong>Definition</strong></th>
<th><strong>Key</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><u><strong>survival</strong></u></td>
<td>是否生存</td>
<td>0 = No, 1 = Yes</td>
</tr>
<tr>
<td>pclass</td>
<td>乘客等级(1/2/3等舱位)</td>
<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>
</tr>
<tr>
<td>sex</td>
<td>性别</td>
<td></td>
</tr>
<tr>
<td>Age</td>
<td>年龄</td>
<td></td>
</tr>
<tr>
<td>sibsp</td>
<td>堂兄弟/妹个数</td>
<td></td>
</tr>
<tr>
<td>parch</td>
<td>父母与小孩个数</td>
<td></td>
</tr>
<tr>
<td>ticket</td>
<td>船票信息</td>
<td></td>
</tr>
<tr>
<td>fare</td>
<td>票价</td>
<td></td>
</tr>
<tr>
<td>cabin</td>
<td>客舱</td>
<td></td>
</tr>
<tr>
<td>embarked</td>
<td>登船港口</td>
<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>
</tr>
</tbody>
</table>
</div>
<h2 id="3-2-查看缺失值和特征类型"><a href="#3-2-查看缺失值和特征类型" class="headerlink" title="3.2 查看缺失值和特征类型"></a>3.2 查看缺失值和特征类型</h2><p>In [1]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#导入数据</span></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line">data = pd.read_csv(<span class="string">'Taitanic data/data.csv'</span>)</div><div class="line">data.info()</div></pre></td></tr></table></figure>
<p>out [1]:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">RangeIndex: <span class="number">891</span> entries, <span class="number">0</span> to <span class="number">890</span></div><div class="line">Data columns (total <span class="number">12</span> columns):</div><div class="line">PassengerId    <span class="number">891</span> non-null int64</div><div class="line">Survived       <span class="number">891</span> non-null int64</div><div class="line">Pclass         <span class="number">891</span> non-null int64</div><div class="line">Name           <span class="number">891</span> non-null object		 &lt;----非数值</div><div class="line">Sex            <span class="number">891</span> non-null object		 &lt;----非数值</div><div class="line">Age            <span class="number">714</span> non-null float64      &lt;----有缺失值</div><div class="line">SibSp          <span class="number">891</span> non-null int64</div><div class="line">Parch          <span class="number">891</span> non-null int64</div><div class="line">Ticket         <span class="number">891</span> non-null object		 &lt;----非数值</div><div class="line">Fare           <span class="number">891</span> non-null float64</div><div class="line">Cabin          <span class="number">204</span> non-null object		 &lt;----有缺失值，非数值</div><div class="line">Embarked       <span class="number">889</span> non-null object		 &lt;----有缺失值，非数值</div><div class="line">dtypes: float64(<span class="number">2</span>), int64(<span class="number">5</span>), object(<span class="number">5</span>)</div><div class="line">memory usage: <span class="number">83.6</span>+ KB</div></pre></td></tr></table></figure></p>
<p>通过<code>data.info()</code>和<code>data.head()</code>，我们可以观察出有多少乘客、特征的数据类型和缺失值。</p>
<p>In [2]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#观察前5行数据</span></div><div class="line">data.head()</div></pre></td></tr></table></figure>
<p>out [2]:</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>

<p>决策树模型的输入要求就是特征必须为数值型的数据，且sklearn无法自动的处理缺失值，因此为了尽快的撸出baseline，我们就不过多的进行分析，先把数据调整成符合模型要求的样子。</p>
<h1 id="4-数据预处理"><a href="#4-数据预处理" class="headerlink" title="4. 数据预处理"></a>4. 数据预处理</h1><h2 id="4-1-特征选择"><a href="#4-1-特征选择" class="headerlink" title="4.1 特征选择"></a>4.1 特征选择</h2><blockquote>
<p>一个正确的数学模型应当在形式上是简单的 —— 吴军，《数学之美》</p>
</blockquote>
<p>特征选择的目的是为了去掉不含信息量或是信息量较少的特征，特征选择和方法很多，如果特征上百个可以选择降维、相关系数分析、卡方检验等方法，既然是暴力的撸出一个baseline，就直接肉眼观察剔除不重要的特征。</p>
<ul>
<li>PassengerId？Name？ 剔除</li>
<li>Ticket 观察一下每张船票都不一样，就跟条形码一样是无用特征</li>
<li>Cabin 缺失值严重，剔除</li>
</ul>
<p>In [3]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#特征选择</span></div><div class="line">data.drop([<span class="string">'Cabin'</span>,<span class="string">'Name'</span>,<span class="string">'Ticket'</span>,<span class="string">'PassengerId'</span>]</div><div class="line">          ,inplace=<span class="keyword">True</span></div><div class="line">          ,axis=<span class="number">1</span></div><div class="line">         )</div></pre></td></tr></table></figure>
<h2 id="4-2-缺失值处理"><a href="#4-2-缺失值处理" class="headerlink" title="4.2 缺失值处理"></a>4.2 缺失值处理</h2><p>由于模型本身没有处理缺失值的能力，我们需要人工的处理缺失值。</p>
<p>缺失值处理的方法常见的有均值填充、中位数填充、归为一类新的特征甚至可以用随机森林或者K-means来预测，还是那句话，先撸出一个model来，怎么快怎么来！</p>
<p>Age大部分数据还是完整的（714／891），因此直接上均值填充填充</p>
<p>In [4]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#处理缺失值</span></div><div class="line">data[<span class="string">'Age'</span>] = data[<span class="string">'Age'</span>].fillna(data[<span class="string">'Age'</span>].mean())</div></pre></td></tr></table></figure>
<p>In [5]:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data.info()</div></pre></td></tr></table></figure></p>
<p>Out [5]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">RangeIndex: <span class="number">891</span> entries, <span class="number">0</span> to <span class="number">890</span></div><div class="line">Data columns (total <span class="number">8</span> columns):</div><div class="line">Survived    <span class="number">891</span> non-null int64</div><div class="line">Pclass      <span class="number">891</span> non-null int64</div><div class="line">Sex         <span class="number">891</span> non-null object</div><div class="line">Age         <span class="number">891</span> non-null float64</div><div class="line">SibSp       <span class="number">891</span> non-null int64</div><div class="line">Parch       <span class="number">891</span> non-null int64</div><div class="line">Fare        <span class="number">891</span> non-null float64</div><div class="line">Embarked    <span class="number">889</span> non-null object    &lt;--缺失值</div><div class="line">dtypes: float64(<span class="number">2</span>), int64(<span class="number">4</span>), object(<span class="number">2</span>)</div><div class="line">memory usage: <span class="number">55.8</span>+ KB</div></pre></td></tr></table></figure>
<p>Embarked 的缺失记录只有2条，怎么快怎么来——直接把那两条记录删掉！</p>
<p>In [6]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#删除含有空值的记录</span></div><div class="line">data = data.dropna(axis=<span class="number">0</span>)</div></pre></td></tr></table></figure>
<p>In [7]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data.info()	<span class="comment">#再次观察数据</span></div></pre></td></tr></table></figure>
<p>Out [7]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">Int64Index: <span class="number">889</span> entries, <span class="number">0</span> to <span class="number">890</span></div><div class="line">Data columns (total <span class="number">8</span> columns):</div><div class="line">Survived    <span class="number">889</span> non-null int64</div><div class="line">Pclass      <span class="number">889</span> non-null int64</div><div class="line">Sex         <span class="number">889</span> non-null object</div><div class="line">Age         <span class="number">889</span> non-null float64</div><div class="line">SibSp       <span class="number">889</span> non-null int64</div><div class="line">Parch       <span class="number">889</span> non-null int64</div><div class="line">Fare        <span class="number">889</span> non-null float64</div><div class="line">Embarked    <span class="number">889</span> non-null object</div><div class="line">dtypes: float64(<span class="number">2</span>), int64(<span class="number">4</span>), object(<span class="number">2</span>)</div><div class="line">memory usage: <span class="number">62.5</span>+ KB</div></pre></td></tr></table></figure>
<p>非常干净了，缺失值的处理到此为止！</p>
<h2 id="4-3-数据转换"><a href="#4-3-数据转换" class="headerlink" title="4.3 数据转换"></a>4.3 数据转换</h2><p>数据转换的目的就是把人看的数据转换成计算机看得懂的数据。</p>
<p>sklearn的模型无法识别male和female，我们需要用0/1来代替</p>
<p>In [8]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#男性为1（True），女性为0(False)</span></div><div class="line">data[<span class="string">'Sex'</span>] = (data[<span class="string">'Sex'</span>] == <span class="string">'male'</span>).astype(<span class="string">'int'</span>)</div></pre></td></tr></table></figure>
<p>再看看Embarked，官方数据集高速我们总共有三个港口分别是C、Q、S</p>
<p>同样的方式处理，映射成0，1，2</p>
<p>In [9]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data[<span class="string">'Embarked'</span>] = data[<span class="string">'Embarked'</span>].map(&#123;<span class="string">'S'</span>:<span class="number">0</span>,<span class="string">'C'</span>:<span class="number">1</span>,<span class="string">'Q'</span>:<span class="number">2</span>&#125;)</div></pre></td></tr></table></figure>
<p>再看看现在数据是什么样子</p>
<p>In [10]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">data.head()</div></pre></td></tr></table></figure>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>7.2500</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>71.2833</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>7.9250</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>53.1000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>8.0500</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<p>到这里一个简单的数据预处理就结束了，没有过多的数据分析，仅仅是把数据处理成模型能够处理的格式。</p>
<h1 id="5-决策树分类"><a href="#5-决策树分类" class="headerlink" title="5. 决策树分类"></a>5. 决策树分类</h1><p>到了这里就是真正的运用机器学习算法了。</p>
<p><strong>第一步，把数据调整成sklearn能够传入的格式</strong>：</p>
<p>sklearn的模型都是把特征和标签分别传入训练，否则一整个数据集模型也无法得知哪个才是特征哪个是标签</p>
<p>In [11]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">X = data.iloc[:,data.columns != <span class="string">"Survived"</span>]</div><div class="line">y = data.iloc[:,data.columns == <span class="string">"Survived"</span>]</div></pre></td></tr></table></figure>
<p><strong>第二步，划分训练集和测试集</strong>：</p>
<p>我们把训练集和测试集按7:3 进行划分</p>
<p>In [12]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</div><div class="line">Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,y,test_size=<span class="number">0.3</span>)</div><div class="line"><span class="comment">#test_size是测试集占总数据集的比例</span></div></pre></td></tr></table></figure>
<p><strong>第三步，导入模型，粗略跑一下查看结果：</strong></p>
<p>sklearn的模型运用基本上分为三步：调用模型、训练模型、评价模型。三行代码如下。</p>
<p>In [13]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#1.声明分类树模型</span></div><div class="line">clf = DecisionTreeClassifier()</div><div class="line"><span class="comment">#2.传入训练集训练模型</span></div><div class="line">clf = clf.fit(Xtrain, Ytrain)</div><div class="line"><span class="comment">#3.传入测试集评价模型</span></div><div class="line">score_ = clf.score(Xtest, Ytest)</div><div class="line">score = cross_val_score(clf,X,y,cv=<span class="number">10</span>).mean() <span class="comment">#交叉验证集准确度</span></div><div class="line"></div><div class="line">print(<span class="string">'测试集准确度:&#123;&#125;\n交叉验证集准确度:&#123;&#125;'</span>.format(score_,score))</div></pre></td></tr></table></figure>
<p>Out [13]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">测试集准确度:<span class="number">0.7715355805243446</span></div><div class="line">交叉验证集准确度:<span class="number">0.7717058222676201</span></div></pre></td></tr></table></figure>
<p>以上，一个非常粗略的baseline就撸出来了。</p>
<h1 id="6-模型参数调整"><a href="#6-模型参数调整" class="headerlink" title="6. 模型参数调整"></a>6. 模型参数调整</h1><p>上面那个粗略的分类树模型都是用默认参数，简单方便但是效果确不是很好，至少调整一个合适的参数还是能够继续提高准确度。</p>
<h2 id="6-1-DecisionTreeClassifier参数介绍"><a href="#6-1-DecisionTreeClassifier参数介绍" class="headerlink" title="6.1 DecisionTreeClassifier参数介绍"></a>6.1 DecisionTreeClassifier参数介绍</h2><p>调参，我们首先要知道有哪些参数以及参数的含义。这里就先列出分类树常用的参数</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数=默认</th>
<th>介绍</th>
</tr>
</thead>
<tbody>
<tr>
<td>criterion=’gini’</td>
<td>gini／entropy 划分节点的指标</td>
</tr>
<tr>
<td>splitter=’best’</td>
<td>节点分支策略</td>
</tr>
<tr>
<td>max_depth=’None’</td>
<td>树最大深度</td>
</tr>
<tr>
<td>min_samples_split=2</td>
<td>一个中间节点分支需要的最少样本（&lt;min_samples_split就不分枝）</td>
</tr>
<tr>
<td>min_samples_leaf=1</td>
<td>分支后叶节点至少需要的最少样本</td>
</tr>
<tr>
<td>random_state</td>
<td>随机数种子</td>
</tr>
</tbody>
</table>
</div>
<p>可以通过试不同的变量来确定一部分参数</p>
<h2 id="6-2-学习曲线调整参数"><a href="#6-2-学习曲线调整参数" class="headerlink" title="6.2 学习曲线调整参数"></a>6.2 学习曲线调整参数</h2><p>In [14]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#分别记录不同参数在测试集和训练集下准确度</span></div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line">tr_entropy = []</div><div class="line">te_entropy = []</div><div class="line"></div><div class="line">tr_gini = []</div><div class="line">te_gini = []</div><div class="line"><span class="comment">#尝试深度从1～10</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">    clf = DecisionTreeClassifier(random_state=<span class="number">25</span></div><div class="line">                                ,max_depth=i+<span class="number">1</span></div><div class="line">                                ,criterion=<span class="string">'entropy'</span> <span class="comment">#尝试信息增益</span></div><div class="line">                                )</div><div class="line">    </div><div class="line">    clf.fit(Xtrain,Ytrain)</div><div class="line">    score_tr = clf.score(Xtrain,Ytrain)</div><div class="line">    score_te = cross_val_score(clf,X,y,cv=<span class="number">10</span>).mean()    </div><div class="line">    tr_entropy.append(score_tr)</div><div class="line">    te_entropy.append(score_te)</div><div class="line">    </div><div class="line">    clf = DecisionTreeClassifier(random_state=<span class="number">25</span></div><div class="line">                                ,max_depth=i+<span class="number">1</span></div><div class="line">                                ,criterion=<span class="string">'gini'</span>   <span class="comment">#尝试基尼系数</span></div><div class="line">                                ) </div><div class="line">    clf.fit(Xtrain,Ytrain)</div><div class="line">    score_tr = clf.score(Xtrain,Ytrain)</div><div class="line">    score_te = cross_val_score(clf,X,y,cv=<span class="number">10</span>).mean()    </div><div class="line">    tr_gini.append(score_tr)</div><div class="line">    te_gini.append(score_te)</div><div class="line"></div><div class="line">    </div><div class="line">fig, (ax0, ax1) = plt.subplots(<span class="number">1</span>,<span class="number">2</span>, figsize=(<span class="number">18</span>, <span class="number">6</span>))    </div><div class="line"></div><div class="line">ax0.plot(range(<span class="number">1</span>,<span class="number">11</span>),tr_entropy,color=<span class="string">'r'</span>,label=<span class="string">'train'</span>)</div><div class="line">ax0.plot(range(<span class="number">1</span>,<span class="number">11</span>),te_entropy,color=<span class="string">'blue'</span>,label=<span class="string">'test'</span>)</div><div class="line">ax0.set_xticks(range(<span class="number">1</span>,<span class="number">11</span>))</div><div class="line">ax0.set_title(<span class="string">'entropy'</span>)</div><div class="line">ax0.legend()</div><div class="line"></div><div class="line">ax1.plot(range(<span class="number">1</span>,<span class="number">11</span>),tr_gini,color=<span class="string">'r'</span>,label=<span class="string">'train'</span>)</div><div class="line">ax1.plot(range(<span class="number">1</span>,<span class="number">11</span>),te_gini,color=<span class="string">'blue'</span>,label=<span class="string">'test'</span>)</div><div class="line">ax1.set_xticks(range(<span class="number">1</span>,<span class="number">11</span>))</div><div class="line">ax0.set_title(<span class="string">'gini'</span>)</div><div class="line">ax1.legend()</div><div class="line"></div><div class="line">print(<span class="string">'entropy上的最好准确度为&#123;&#125;\njini上的最好准确度为&#123;&#125;'</span>.format(max(te_entropy),max(te_gini)))</div></pre></td></tr></table></figure>
<p>Out [14]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">entropy上的最好准确度为0.8177860061287026</div><div class="line">jini上的最好准确度为0.8177987742594486</div></pre></td></tr></table></figure>
<p><img src="https://image.littlebeans.cn/images/2019/01/31/154aee42739a0324b49d44a1505f5a20.png" alt="154aee42739a0324b49d44a1505f5a20.png"></p>
<p>比起默认参数，经过参数的粗略调整后，模型在测试集上的准确度得到了明显提升</p>
<p>可以观察出当最大深度为3时，拟合效果较好，且两种划分情况准确度都十分相近</p>
<h2 id="6-3-网格搜索调整参数"><a href="#6-3-网格搜索调整参数" class="headerlink" title="6.3 网格搜索调整参数"></a>6.3 网格搜索调整参数</h2><p>如果参数的取值范围很大，参数个数也很多，这么一个个参数人为的去慢慢尝试是非常消耗时间的，因此我们可以调用sklearn的GridSearchCV来帮助我们寻找合适的参数。</p>
<p>网格参数搜索的本质其实就是把每个参数的取值排列组合一个个帮我们尝试，并且返回交叉验证准确度最好的一组参数。</p>
<blockquote>
<p>在调用网格参数搜索前最好先确定参数的大致范围，否则相当消耗时间</p>
</blockquote>
<p>In [15]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#网格搜索：能够帮助我们调整多个参数的技术---枚举</span></div><div class="line"></div><div class="line"><span class="comment">#网格搜索：能够帮助我们调整多个参数的技术---枚举</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</div><div class="line"></div><div class="line">gini_threholds = np.linspace(<span class="number">0</span>,<span class="number">0.5</span>,<span class="number">20</span>)</div><div class="line"></div><div class="line"></div><div class="line">parameters = &#123;<span class="string">'criterion'</span>:(<span class="string">'gini'</span>,<span class="string">'entropy'</span>)</div><div class="line">              ,<span class="string">'splitter'</span>:(<span class="string">'best'</span>,<span class="string">'random'</span>)</div><div class="line">              ,<span class="string">'max_depth'</span>:[*range(<span class="number">2</span>,<span class="number">5</span>)]</div><div class="line">              ,<span class="string">'min_samples_leaf'</span>:[*range(<span class="number">1</span>,<span class="number">10</span>,<span class="number">2</span>)]</div><div class="line">          <span class="comment">#    ,'min_impurity_decrease':np.linspace(0,0.5,20)</span></div><div class="line">    </div><div class="line">&#125;</div><div class="line"></div><div class="line">clf = DecisionTreeClassifier(random_state=<span class="number">25</span>)</div><div class="line">gs = GridSearchCV(clf,parameters,cv=<span class="number">10</span>)</div><div class="line">gs.fit(Xtrain,Ytrain)</div></pre></td></tr></table></figure>
<p>In [16]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">gs.best_params_ <span class="comment">#我们输入参数和参数取值中，最佳组合</span></div></pre></td></tr></table></figure>
<p>Out [16]:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&#123;&apos;criterion&apos;: &apos;gini&apos;,</div><div class="line"> &apos;max_depth&apos;: 4,</div><div class="line"> &apos;min_samples_leaf&apos;: 1,</div><div class="line"> &apos;splitter&apos;: &apos;random&apos;&#125;</div></pre></td></tr></table></figure>
<p>用训练的参数导入模型</p>
<p>In [17]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">clf = DecisionTreeClassifier(random_state=<span class="number">20</span></div><div class="line">                            ,criterion=<span class="string">'gini'</span></div><div class="line">                            ,max_depth=<span class="number">4</span></div><div class="line">                            ,min_samples_leaf=<span class="number">1</span></div><div class="line">                            ,splitter=<span class="string">'random'</span></div><div class="line">                            )</div><div class="line">clf = clf.fit(Xtrain, Ytrain)</div><div class="line">cross_val_score(clf,X,y,cv=<span class="number">10</span>).mean()</div></pre></td></tr></table></figure>
<p>Out [17]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="number">0.806511746680286</span></div></pre></td></tr></table></figure>
<p>比之前稍差了点，这其实是因为GridSearchCV在评判的参数好坏的标准是把传入的训练集又分为了训练集和测试集，并通过交叉验证求平均找出准确率最好的参数组合；而之前的算法的准确率是直接用训练集训练并用全部数据集交叉验证的结果，因此两者在评判对象上有所不同，如果两者准确率相差不大，那就任选即可。</p>
<blockquote>
<p>如果上面的解释没看懂，那就记住如果自己调试的参数和网格搜索结果相差不大，那说明你已经逼近了调参结果的上限，任选一个就好了。</p>
</blockquote>
<h1 id="7-上传到kaggle查看得分"><a href="#7-上传到kaggle查看得分" class="headerlink" title="7. 上传到kaggle查看得分"></a>7. 上传到kaggle查看得分</h1><p>把官方的测试数据集进行预测并上传到官网</p>
<p>刚刚的模型是训练集经过处理才能使用的，因此测试集也要做同样处理。</p>
<p>In [18]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">test = pd.read_csv(<span class="string">'Taitanic data/test.csv'</span>)</div><div class="line">test.info()</div></pre></td></tr></table></figure>
<p>Out [18]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">RangeIndex: <span class="number">418</span> entries, <span class="number">0</span> to <span class="number">417</span></div><div class="line">Data columns (total <span class="number">11</span> columns):</div><div class="line">PassengerId    <span class="number">418</span> non-null int64</div><div class="line">Pclass         <span class="number">418</span> non-null int64</div><div class="line">Name           <span class="number">418</span> non-null object</div><div class="line">Sex            <span class="number">418</span> non-null object</div><div class="line">Age            <span class="number">332</span> non-null float64		&lt;----缺失</div><div class="line">SibSp          <span class="number">418</span> non-null int64</div><div class="line">Parch          <span class="number">418</span> non-null int64</div><div class="line">Ticket         <span class="number">418</span> non-null object</div><div class="line">Fare           <span class="number">417</span> non-null float64	    &lt;----缺失</div><div class="line">Cabin          <span class="number">91</span> non-null object</div><div class="line">Embarked       <span class="number">418</span> non-null object</div><div class="line">dtypes: float64(<span class="number">2</span>), int64(<span class="number">4</span>), object(<span class="number">5</span>)</div><div class="line">memory usage: <span class="number">36.0</span>+ KB</div></pre></td></tr></table></figure>
<p>发现和训练集不同的是‘Fare’特征有一个缺失值，这需要小心不能忘了处理</p>
<p>In [19]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#把测试集预处理操作封装</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">clean_data</span><span class="params">(data)</span>:</span></div><div class="line">    data = data.drop([<span class="string">'Cabin'</span>,<span class="string">'Name'</span>,<span class="string">'Ticket'</span>,<span class="string">'PassengerId'</span>]</div><div class="line">          ,axis=<span class="number">1</span></div><div class="line">         )</div><div class="line">    data[<span class="string">'Age'</span>] = data[<span class="string">'Age'</span>].fillna(data[<span class="string">'Age'</span>].mean())</div><div class="line">    data[<span class="string">'Fare'</span>] = data[<span class="string">'Fare'</span>].fillna(data[<span class="string">'Fare'</span>].mean())   <span class="comment">#</span></div><div class="line">    data = data.dropna(axis=<span class="number">0</span>)</div><div class="line">    data[<span class="string">'Sex'</span>] = (data[<span class="string">'Sex'</span>] == <span class="string">'male'</span>).astype(<span class="string">'int'</span>)</div><div class="line">    data[<span class="string">'Embarked'</span>] = data[<span class="string">'Embarked'</span>].map(&#123;<span class="string">'S'</span>:<span class="number">0</span>,<span class="string">'C'</span>:<span class="number">1</span>,<span class="string">'Q'</span>:<span class="number">2</span>&#125;)</div><div class="line">    <span class="keyword">return</span> data</div></pre></td></tr></table></figure>
<p>In [20]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">test_data = clean_data(test)</div><div class="line">res = 	pd.concat([test[<span class="string">'PassengerId'</span>],pd.DataFrame(clf.predict(test_data))],axis=<span class="number">1</span>)</div><div class="line">res.columns = [<span class="string">'PassengerId'</span>,<span class="string">'Survived'</span>]</div><div class="line">res.to_csv(<span class="string">"result.csv"</span>,sep=<span class="string">','</span>,index=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<p>提交结果查看得分，top20%的baseline，还行</p>
<p><img src="https://image.littlebeans.cn/images/2019/01/31/5C150B26-F6E5-4F43-B315-C96E3231C164.jpg" alt="5C150B26-F6E5-4F43-B315-C96E3231C164.jpg"></p>
<h1 id="8-总结"><a href="#8-总结" class="headerlink" title="8 总结"></a>8 总结</h1><p>完成了一次完整的kaggle还是很有成就感的，不过依然有很多瑕疵。</p>
<p>kaggle最重要的特征工程几乎被我一笔带过，数据没有经过严密的统计分析，有句话叫“特征工程决定了最后结果的上限，而机器学习算法只是在逼近这个上限”。特征上还有很多事情可以做，例如：</p>
<ul>
<li>Age可以尝试Random forest、SVM等算法预测填充</li>
<li>Cabin可以保留，把缺失值当作一类，非缺失值当作一类</li>
<li>sibsp，parch也可以推测出一个人的年龄区间</li>
<li>sibsp，parch两个特征可以用一个新的特征“家庭成员数量”代替试试</li>
<li>… …</li>
</ul>
<p>甚至尝试不同的模型，对于不同的模型又会有不同的数据处理方式，例如降为、归一化、One-hot编码等，如果把泰坦尼克号数据集的内容吃透对于其他数据集也能得心应手了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1. 引言&quot;&gt;&lt;/a&gt;1. 引言&lt;/h1&gt;&lt;p&gt;检验学习成果最快的方式就是去实战，kaggle上提供了各式各样练手和比赛的数据集，”Titanic: Machine Learning from Disaster”就是最经典的入门比赛，既适合经验丰富的Data scientist去深入分析争取top3%的成绩，也适合新手应用数据集对所学习的分类算法来练手。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;应用机器学习，千万不要一上来就试图做到完美，先撸一个baseline的model出来，再进行后续的分析步骤，一步步提高。—— Andrew Ng&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="kaggle" scheme="http://yoursite.com/tags/kaggle/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="决策树" scheme="http://yoursite.com/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>python向量化思维编程的总结</title>
    <link href="http://yoursite.com/2019/01/25/Vectorization/"/>
    <id>http://yoursite.com/2019/01/25/Vectorization/</id>
    <published>2019-01-25T08:51:15.000Z</published>
    <updated>2019-01-25T12:19:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="我的python为什么比较慢"><a href="#我的python为什么比较慢" class="headerlink" title="我的python为什么比较慢"></a>我的python为什么比较慢</h1><p>刚刚开始接触python时，以为学习了基本的语法和数据结构以及常用包的API就算是掌握了这门语言，但是写起算法时，除了感受到语法上的精简外也看不到这门语言的高效之处。</p>
<p>有一个很大的原因就是沿用了以前java／c的编程思维，但是python处理数据所面对的问题常常需要大量的迭代、累加和样本的重复计算，用c语言的编程习惯很容易上来就是for循环，例如写矩阵的乘法用暴力三次方的复杂度来解决.</p>
<a id="more"></a>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//矩阵乘法，3个for循环搞定    </span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">MulMatrix</span><span class="params">(<span class="keyword">int</span>** matrixA, <span class="keyword">int</span>** matrixB, <span class="keyword">int</span>** matrixC)</span>    </span></div><div class="line">&#123;    </div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; ++i)     </div><div class="line">    &#123;    </div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; ++j)     </div><div class="line">        &#123;    </div><div class="line">            matrixC[i][j] = <span class="number">0</span>;    </div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; <span class="number">2</span>; ++k)     </div><div class="line">            &#123;    </div><div class="line">                matrixC[i][j] += matrixA[i][k] * matrixB[k][j];    </div><div class="line">            &#125;    </div><div class="line">        &#125;    </div><div class="line">    &#125;    </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>如果在python上还沿用这种思维，那仅仅是换个语法重新实现这个算法罢了，完全没有发挥出python的优势，甚至用C写的效率还会更高。</p>
<p>python之所以在数据分析上有它的一席之地，是因为他快。如何发挥出它的效率，那就需要<strong>向量化的编程思维</strong>。</p>
<p>利用python专门处理向量／矩阵运算的包——numpy，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。</p>
<h1 id="向量化编程的例子"><a href="#向量化编程的例子" class="headerlink" title="向量化编程的例子"></a>向量化编程的例子</h1><h2 id="例1"><a href="#例1" class="headerlink" title="例1:"></a>例1:</h2><script type="math/tex; mode=display">
h_\theta(x) = \theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3</script><p>令：$\theta=[\theta_0,\theta_1,\theta_2,\theta_3]^T$；$x=[1,x_1,x_2,x_3.x_4]^T$</p>
<p>可以写成：</p>
<script type="math/tex; mode=display">
h_\theta(x)=\theta^Tx</script><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#python</span></div><div class="line">t = np.array([t1,t2,t3,t4])</div><div class="line">x = np.array([<span class="number">1</span>,x1,x2,x3,x4])</div><div class="line">h = t.T @ x 	<span class="comment"># '@'相当于向量相乘</span></div></pre></td></tr></table></figure>
<h2 id="例2"><a href="#例2" class="headerlink" title="例2:"></a>例2:</h2><script type="math/tex; mode=display">
J(\theta) = \frac{1}{m}\sum_{i=1}^{m}[-y^{(i)}log(h_{\theta}(x^{(i)}))-(1-y^{(i)})log(1-h_{\theta}(x^{(i)}))]</script><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#各变量维度</span></div><div class="line"><span class="comment">#x:(m,n)</span></div><div class="line"><span class="comment">#y:(m,1)</span></div><div class="line"><span class="comment">#theta:(n,1)</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">computer_cost</span><span class="params">(theta,x,y)</span>:</span>   </div><div class="line">    m = len(x)</div><div class="line">    h = sigmoid(x@theta) <span class="comment"># (m,n)*(n,1)=(m,1) </span></div><div class="line">    first = np.log(h).T @ y <span class="comment">#(m,1).T*(m,1) = (1,m)*(m,1)=(1,1)</span></div><div class="line">    second = np.log(<span class="number">1</span>-h).T @ (<span class="number">1</span>-y)</div><div class="line">    cost = -(first+second)/m</div><div class="line">    <span class="keyword">return</span> cost</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;我的python为什么比较慢&quot;&gt;&lt;a href=&quot;#我的python为什么比较慢&quot; class=&quot;headerlink&quot; title=&quot;我的python为什么比较慢&quot;&gt;&lt;/a&gt;我的python为什么比较慢&lt;/h1&gt;&lt;p&gt;刚刚开始接触python时，以为学习了基本的语法和数据结构以及常用包的API就算是掌握了这门语言，但是写起算法时，除了感受到语法上的精简外也看不到这门语言的高效之处。&lt;/p&gt;
&lt;p&gt;有一个很大的原因就是沿用了以前java／c的编程思维，但是python处理数据所面对的问题常常需要大量的迭代、累加和样本的重复计算，用c语言的编程习惯很容易上来就是for循环，例如写矩阵的乘法用暴力三次方的复杂度来解决.&lt;/p&gt;
    
    </summary>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
</feed>
